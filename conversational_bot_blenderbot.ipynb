{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThiJsbfB117s"
      },
      "source": [
        "# Build a simple conversational agent in python using the pre-trained Blenderbot model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrlR0wJJ117v"
      },
      "source": [
        "## What is Blenderbot?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qCnxFif117w"
      },
      "source": [
        "An open source chatbot that builds long-term memory and searches the internet\n",
        "* A chatbot with its own long-term memory and the ability to access the internet. It outperforms existing models in terms of longer conversations over multiple sessions and is more knowledgeable and has more factual consistency, according to human evaluators.\n",
        "\n",
        "* The model stores pertinent knowledge gleaned during the conversation to a long-term memory store, and uses this experience to engage in long-term conversation sessions.\n",
        "\n",
        "* During conversation, the model can search the internet by generating its own search queries, reading the results, and taking them into account when formulating a response.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "xJ4LSvLN1_Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "dnczEY3t2QCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask"
      ],
      "metadata": {
        "id": "nSFJvAYi4XP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_TPf1xo117x"
      },
      "source": [
        "## Import and download the pre-trained Blenderbot model from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWuKCGyK117x"
      },
      "outputs": [],
      "source": [
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iuuuXhs117y"
      },
      "outputs": [],
      "source": [
        "#download and setup the model and tokenizer\n",
        "model_name = 'facebook/blenderbot-400M-distill'\n",
        "#instantiate the tokenizer and the model itself on the model name.\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try to build a conversation with the bot\n"
      ],
      "metadata": {
        "id": "RrqSNfbC3Iox"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMsYR1CO117y"
      },
      "outputs": [],
      "source": [
        "#making an utterance \n",
        "utterance = \"My name is Manel, I like Coffee and coding\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pykaQ7Js117y"
      },
      "outputs": [],
      "source": [
        "#tokenize the utterance\n",
        "inputs = tokenizer(utterance, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1xpxoxK117z",
        "outputId": "ec47a2e4-690d-44e6-debd-257ea03e74b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 60 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "#generate model results\n",
        "result = model.generate(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmCvy88aFYte",
        "outputId": "071bf7d9-ffa1-49e4-8a85-702e76e15aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   1, 3490,  287, 2273,  304,   19,  395, 1356,  315,  268,  343,  408,\n",
              "          274,   21,  281,  398, 4108,  371,  731,   21,    2]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i7anYz8N117z",
        "outputId": "0ba80c87-baa8-49ec-8cf0-534b7affda82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Nice to meet you, my name is samantha. I like coffee as well.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tokenizer.decode(result[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "GnibwmU1EgXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatting 10 times with greedy search\n",
        "for step in range(10):\n",
        "    # take user input\n",
        "    text = input(\">> You:\")\n",
        "    # encode the input \n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "  \n",
        "    # generate a bot response\n",
        "    result = model.generate(**inputs)\n",
        "    #print the output\n",
        "    output = tokenizer.decode(result[0])\n",
        "    print(f\">>MyBot: {output}\")"
      ],
      "metadata": {
        "id": "epbr8GYDEgZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foFsr2y9Erv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}